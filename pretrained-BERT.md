# BERT Mountain
1. BERT
2. Transformer
3. Attention
4. Encoder-Decoder & Bi-LSTM
5. RNN & LSTM

nb: _RNN & LSTM is the most basic_

# Pretrained representation
- Context-free:
  - Word2vec
  - Glove
- Contextual
  - Unidirectional
  - Bidirectional
    - BERT (Bidirectional Encoder Representation from Transformer)
